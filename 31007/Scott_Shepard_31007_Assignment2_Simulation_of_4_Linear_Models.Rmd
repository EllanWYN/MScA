---
title: "Simulation of 4  Linear Models"
author: "Scott Shepard"
date: "4/15/2018"
output:
  html_document:
    df_print: paged
subtile: Week 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Set the values of slope (a) and intercept (b) parameters. Set the sample lengths to 1,000.

```{r}
# Slope and Intercept
a <- 0.8; b <- 0.1
nSample <- 1000
```

## 1. Model 1

Simulate and plot Model1:  
  - input variable X ~ Norm(μ=3,σ=2.5)  
  - model residuals Eps ~ Norm(μ=0,σ=1.5)  
Use set.seed(111) to simulate X and set.seed(1112131415) to simulate Eps.

```{r}
set.seed(111)
X = rnorm(nSample, 3, 2.5)

set.seed(1112131415)
Eps = rnorm(nSample, 0, 1.5)

Y = a*X + b + Eps

LinearModel1 = data.frame(Y, X, Eps)

head(LinearModel1)
```

```{r}
plot(LinearModel1$X,LinearModel1$Y)
```

**Plot the residuals of the model.**

```{r}
plot(LinearModel1$Eps,type="l")
```

## 2. Model 2

Simulate and plot Model2:  
  - input variable X ~ Norm(μ=3,σ=2.5)   
  - model residuals Eps ~ Unif(min=−4.33,max=4.33).  

Use the same realization of X as in the first model.  
Use the same seed set.seed(1112131415) to simulate Eps.  
Plot the residuals of the model.

```{r}
set.seed(1112131415)
Eps = runif(nSample, -4.33, 4.33)

Y = a*X + b + Eps

LinearModel2 = data.frame(Y, X, Eps)

head(LinearModel2)
```

```{r}
plot(LinearModel2$X,LinearModel2$Y)
```

```{r}
plot(LinearModel2$Eps,type="l")
```

## 3. Model 3

Simulate and plot Model3:  
  - input variable X ~ Norm^(μ=3,σ=2.5)  
  - model residuals Eps ~ Cauchi*(location=0,scale=0.3).  

Use the same realization of X as in the first model.  
Use the same seed set.seed(1112131415) to simulate Eps.  
Plot the residuals of the model.

```{r}
set.seed(1112131415)
Eps <- rcauchy(nSample, 0, 0.3)
Y = a*X + b + Eps

LinearModel3 = data.frame(X, Y, Eps)

head(LinearModel3)
```

```{r}
plot(LinearModel3$X,LinearModel3$Y)
```

```{r}
plot(LinearModel3$Eps,type="l")
```

Estimate the standard deviation of the residuals
```{r}
sd(LinearModel3$Eps)
```

Generate another 5 samples of residuals without any seed specification and estimate standard deviations for each of them.

```{r}
Eps1<-rcauchy(n=nSample,location=0,scale=.3)
Eps2<-rcauchy(n=nSample,location=0,scale=.3)
Eps3<-rcauchy(n=nSample,location=0,scale=.3)
Eps4<-rcauchy(n=nSample,location=0,scale=.3)
Eps5<-rcauchy(n=nSample,location=0,scale=.3)
c(sd(Eps1),sd(Eps2),sd(Eps3),sd(Eps4),sd(Eps5))
```

Note the irregularity of standard deviations from sample to sample.

**How do you interpret this observation?**

The standard deviation of the cauchy distribtion varies wildly even though 
the inputs to all the different samples are the same. With a normal 
distribution the standard deviations with a sample size of 1000 would be 
tightly clustered together. The cauchy distribution has an unpredictable 
variance so each repeated sample is going to look completely different from
the previous set.

## 4. Model 4  

Simulate and plot Model4:  
  - input variable X ~ Norm(μ=3,σ=2.5)  
  - model residuals Eps ~ a heteroscedastic process.  

Use the same realization of X as in the first model.  
Use the same seed.  
Plot the residuals of the model.  

Heteroscedasticity means that even though the model residuals Eps may be generated by a normal distribution, the standard deviation parameters for different sub samples are different.

Create the process of standard deviations in which the first 50 observations have sigma=2, followed by 75 observations with sigma=3.4, followed by 75 observations with sigma=0.8 and concluded by 50 observations with sigma=2.6.

Plot the trajectory of standard deviations of total length nSample=1000.  
```{r}
sd.Values<-c(2,3.4,.8,2.6)
sd.process<-rep(c(rep(sd.Values[1],50),
                  rep(sd.Values[2],75),
                  rep(sd.Values[3],75),
                  rep(sd.Values[4],50)),
            4)
            
plot(sd.process,type="l")
```

Simulate the linear model residuals Eps with changing standard deviations.

```{r}
set.seed(1112131415);
Eps<-rnorm(nSample)*sd.process
```

** Plot the residuals. **

```{r}
plot(Eps,type="l")
```

Observe how heteroscedasticity transforms normal distribution into leptokurtic distribution

```{r}
Xvariable<-(100*floor(min(Eps))):(100*ceiling(max(Eps)))
Xvariable<-Xvariable/100
# Plot the sample distribution and the theo. distribution
plot(Xvariable,dnorm(Xvariable,mean=mean(Eps),sd=sd(Eps)),type="l",
      ylim=c(0,.3),col="black",ylab="Distribution of Eps",xlab="")
lines(density(Eps),col="red")
```

Generate LinearModel4.
Plot it.

```{r}
Y <- a*X+b+Eps
LinearModel4 <- data.frame(Y, X)
plot(LinearModel4$X,LinearModel4$Y)
```

## 5. Effect of Residual Distribution on Correlation

Calculate the theoretical ρ2 for the “correct model” which is LinearModel1.

```{r}
# Theoretical Rho^2
# Theoretical.Rho.Squared<-(a*sd.X)^2/((a*sd.X)^2+sd.Eps^2)
# Theoretical.Rho.Squared
```

```{r}
c(cor(LinearModel1$X,LinearModel1$Y)^2,
  cor(LinearModel2$X,LinearModel2$Y)^2,
  cor(LinearModel3$X,LinearModel3$Y)^2,
  cor(LinearModel4$X,LinearModel4$Y)^2)
```

**How do you interpret the results?**

## 6. Estimation of Linear Model

Estimate parameters a,b,σ using the function `lm()`

```{r}
m1<-lm(Y~X,data=LinearModel1)
```

Explore the object m1

```{r}
summary(m1)
```

```{r}
names(summary(m1))
```

```{r}
summary(m1)$r.squared
```

```{r}
summary(m1)$coeff
```

```{r}
summary(m1)$sigma^2
```

```{r}
var(summary(m1)$residuals)
```

**Note the difference between `summary(m1)$sigma^2` and `var(summary(m1)$residuals)`.**

```{r}
var(summary(m1)$residuals)*999/998
```

Estimate the same parameters using the method of moments directly.

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```
